{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c3cae5",
   "metadata": {
    "id": "494a8c17"
   },
   "source": [
    "# CS 584 Assignment 3 -- Language Model\n",
    "\n",
    "#### Name: Agamdeep S. Chopra\n",
    "\n",
    ]
  },
  {
   "cell_type": "markdown",
   "id": "9403aa9a",
   "metadata": {
    "id": "9a2591a0"
   },
   "source": [
    "## In this assignment, you are required to follow the steps below:\n",
    "1. Review the lecture slides.\n",
    "2. Implement N-gram language modeling.\n",
    "3. Implement RNN language modeling.\n",
    "\n",
    "*** Please read the code and comments very carefully and install these packages (NumPy, sklearn, and tqdm) before you start ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fc8e5eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a23584bf",
    "outputId": "feb54288-555f-40fa-9358-b4aed6a5a8ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (1.20.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (4.60.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from scikit-learn) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib) (2021.5.30)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: spacy in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy) (52.0.0.post20210125)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy) (4.60.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy) (8.0.10)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy) (1.20.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from en-core-web-sm==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.20.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (20.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.60.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.11.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\agama\\anaconda3\\envs\\ai\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy scikit-learn tqdm matplotlib\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eff6ec",
   "metadata": {
    "id": "a4b34034"
   },
   "source": [
    "## 0. Data Process\n",
    "Run the following cells to preprocess training data, validation data, and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c3b162",
   "metadata": {
    "id": "681c2be5"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef1b5023",
   "metadata": {
    "id": "6dca548c"
   },
   "outputs": [],
   "source": [
    "train_texts = []\n",
    "with open('./data/train.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        train_texts.append(line)\n",
    "        \n",
    "valid_texts = []\n",
    "with open('./data/valid.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        valid_texts.append(line)\n",
    "        \n",
    "test_texts = []\n",
    "with open('./data/input.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        test_texts.append(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142f5a97",
   "metadata": {
    "id": "3121ada5"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fba47263",
   "metadata": {
    "id": "806dfdea"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from string import punctuation\n",
    "\n",
    "class Preprocesser(object):\n",
    "    def __init__(self, punctuation=True, url=True, number=True):\n",
    "        self.punctuation = punctuation\n",
    "        self.url = url\n",
    "        self.number = number\n",
    "    \n",
    "    def apply(self, text):\n",
    "        \n",
    "        text = self._lowercase(text)\n",
    "        text = text.replace('<unk>', '')\n",
    "        text = text.replace('\\n', '')\n",
    "        \n",
    "        if self.url:\n",
    "            text = self._remove_url(text)\n",
    "            \n",
    "        if self.punctuation:\n",
    "            text = self._remove_punctuation(text)\n",
    "            \n",
    "        if self.number:\n",
    "            text = self._remove_number(text)\n",
    "        \n",
    "        \n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "            \n",
    "        return text\n",
    "    \n",
    "        \n",
    "    def _remove_punctuation(self, text):\n",
    "        ''' Please fill this function to remove all the punctuations in the text\n",
    "        '''\n",
    "        ### Start your code\n",
    "        \n",
    "        text = ''.join(c for c in text if c not in punctuation)\n",
    "        \n",
    "        ### End\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def _remove_url(self, text):\n",
    "        ''' Please fill this function to remove all the urls in the text\n",
    "        '''\n",
    "        ### Start your code\n",
    "        \n",
    "        text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', text)\n",
    "        \n",
    "        ### End\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def _remove_number(self, text):\n",
    "        ''' Please fill this function to remove all the numbers in the text\n",
    "        '''\n",
    "        \n",
    "        ### Start your code\n",
    "        text = ''.join([i for i in text if not i.isdigit()])\n",
    "        \n",
    "        ### End\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def _lowercase(self, text):\n",
    "        ''' Please fill this function to lower the text\n",
    "        '''\n",
    "        \n",
    "        ### Start your code\n",
    "        \n",
    "        text = text.lower()\n",
    "        \n",
    "        ### End\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    \n",
    "preprocesser = Preprocesser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c04ad0",
   "metadata": {
    "id": "407f9491"
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09256a1e",
   "metadata": {
    "id": "adb65b9b"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize(text):\n",
    "    ''' Since it is a language model, we don't need to remove the stop words.\n",
    "    '''\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    \n",
    "    return tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c814097",
   "metadata": {
    "id": "aa948370"
   },
   "source": [
    "## 1. N-gram (50 points)\n",
    "In this section, you are required to implement an N-gram model for language modeling and two smoothing methods.\n",
    "1. Implement N-gram (Bigram).\n",
    "2. Implement Good Turing smoothing.\n",
    "3. Implement Kneser-Ney smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f153f4",
   "metadata": {
    "id": "79930b64"
   },
   "source": [
    "### 1.1 Implement a bigram for language modeling (fill the code, 10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "686d8f68",
   "metadata": {
    "id": "85044a64"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class BiGram(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        ''' Construction function of BiGram.\n",
    "            Params:\n",
    "                uni_count: a dictionary with default value 0\n",
    "                bi_count: a dictionary that each value is a dictionary with default value 0\n",
    "        '''\n",
    "\n",
    "        self.uni_count = defaultdict(lambda: 0)\n",
    "        self.bi_count = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        \n",
    "        \n",
    "    def fit(self, texts):\n",
    "        self._unigram_count(texts)\n",
    "        self._bigram_count(texts)\n",
    "        \n",
    "    \n",
    "    def _unigram_count(self, texts):\n",
    "        ''' Count tokens, and store in self.uni_count\n",
    "            Input\n",
    "                texts: a list of text\n",
    "        '''\n",
    "        \n",
    "        ### Start you code\n",
    "        toks = []\n",
    "        for sen in tqdm(texts):\n",
    "            for word in tokenize(Preprocesser().apply(sen[1:])):\n",
    "                toks.append(word)\n",
    "        for word in tqdm(toks):\n",
    "            if word not in self.uni_count.keys():\n",
    "                for target in toks:\n",
    "                    if target == word:\n",
    "                        self.uni_count[word] += 1   \n",
    "        ### End\n",
    "            \n",
    "    \n",
    "    \n",
    "    def _bigram_count(self, texts):\n",
    "        ''' Count tokens in bigram way, and store in self.bi_count\n",
    "            Input\n",
    "                texts: a list of text\n",
    "        '''\n",
    "        \n",
    "        ### Start you code\n",
    "        btoks = []\n",
    "        for sen in tqdm(texts):\n",
    "            btoks.append(tokenize(Preprocesser().apply(sen[1:])))\n",
    "        for sen in tqdm(btoks):\n",
    "            for i in range(len(sen) - 1):\n",
    "                word1,word2 = sen[i],sen[i+1]\n",
    "                if self.bi_count[word1][word2] == 0:\n",
    "                    for senn in btoks:\n",
    "                        for j in range(len(senn) - 1):\n",
    "                            if senn[j] == word1 and senn[j+1] == word2:\n",
    "                                self.bi_count[word1][word2] += 1\n",
    "        ### End\n",
    "    \n",
    "    \n",
    "    def probability(self, w1, w2):\n",
    "        ''' Given two tokens, calculate the bigram probability\n",
    "            Input\n",
    "                w1: the first token of bigram\n",
    "                w2: the second token of bigram\n",
    "        '''\n",
    "        prob = 0.\n",
    "        \n",
    "        ### Start you code\n",
    "        \n",
    "        try:\n",
    "            prob = self.bi_count[w1][w2] / self.uni_count[w1]\n",
    "        except:\n",
    "            prob = 1E-2\n",
    "        \n",
    "        ### End\n",
    "        \n",
    "        return prob\n",
    "    \n",
    "    \n",
    "    def predict(self, w):\n",
    "        ''' Given a word, find a word with the highest probability\n",
    "            Input\n",
    "                w: a word\n",
    "                \n",
    "            Hint: utilize self.probability(w, w2) to find which w2 has the highest probability\n",
    "        '''\n",
    "        \n",
    "        w_next = None\n",
    "        \n",
    "        ### Start your code\n",
    "        \n",
    "        w_next_list = list(self.bi_count[w].keys())\n",
    "        \n",
    "        prob_list = []\n",
    "        \n",
    "        for w2 in w_next_list:\n",
    "            prob_list.append(self.probability(w, w2))\n",
    "            \n",
    "        w_next = w_next_list[prob_list.index(max(prob_list))]\n",
    "        \n",
    "        ### End\n",
    "        \n",
    "        return w_next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def4cd38",
   "metadata": {
    "id": "bdd9a515"
   },
   "source": [
    "### 1.2 Implement Good Turing smoothing (fill the code, 15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "c118e9f9",
   "metadata": {
    "id": "94009b7e"
   },
   "outputs": [],
   "source": [
    "class GoodTuring(object):\n",
    "    \n",
    "    def __init__(self, bigram):\n",
    "        ''' Construction function of Good Turing.\n",
    "            Input\n",
    "                bigram: Bigram model\n",
    "            Params:\n",
    "                uni_count: a dictionary with default value 0\n",
    "                bi_count: a dictionary that each value is a dictionary with default value 0\n",
    "                -----------------\n",
    "                For bigram\n",
    "                bi_nc: a dictionary with default value 0, the count of things we've seen c times.\n",
    "                bi_c_star: (c+1)*N_c+1 / N_c, page 64 of slides (lecture 5).\n",
    "                bi_N: \\sum c*N_c, page 64 of slides (lecture 5).\n",
    "                \n",
    "                For unigram\n",
    "                uni_nc: a dictionary with default value 0, the count of things we've seen c times.\n",
    "                uni_c_star: (c+1)*N_c+1 / N_c, page 64 of slides (lecture 5).\n",
    "                uni_N: \\sum c*N_c, page 64 of slides (lecture 5).\n",
    "            \n",
    "        '''\n",
    "        self.uni_count = bigram.uni_count\n",
    "        self.bi_count = bigram.bi_count\n",
    "        \n",
    "        self.uni_nc = defaultdict(lambda: 0)\n",
    "        self.bi_nc = defaultdict(lambda: 0)\n",
    "        \n",
    "        self.uni_c_star = defaultdict(lambda: 0)\n",
    "        self.bi_c_star = defaultdict(lambda: 0)\n",
    "        \n",
    "        self.uni_N = 0\n",
    "        self.bi_N = 0\n",
    "        \n",
    "        \n",
    "    def fit(self, texts):\n",
    "        self._calc_N_c()\n",
    "        self._calc_c_star_and_N()\n",
    "        \n",
    "    \n",
    "    def _calc_N_c(self):\n",
    "        ''' Count the frequency of frequency c, and store to self.nc.\n",
    "            Page 64 of slides (lecture 5)\n",
    "            Hint: You could directly utililze self.bi_count and self.uni_count to calculate N_c\n",
    "        '''\n",
    "        \n",
    "        ### Start you code\n",
    "        #uni_key = list(self.uni_count.keys())\n",
    "        #print(uni_count[uni_key[0]])\n",
    "        freq_uniq = []\n",
    "        freq_list = list(self.uni_count.values())\n",
    "        #print(freq_list, len(freq_list))\n",
    "        for i in freq_list:\n",
    "            if i not in freq_uniq:\n",
    "                freq_uniq.append(i)\n",
    "        freq_uniq = sorted(freq_uniq, reverse=True)\n",
    "        #print(freq_uniq)\n",
    "        for i in freq_uniq:\n",
    "            for j in freq_list:\n",
    "                if i == j:\n",
    "                    self.uni_nc[i] += 1\n",
    "        freq_uniq = []\n",
    "        freq_list = []\n",
    "        for i in list(self.bi_count.values()):\n",
    "            for j in list(i.values()):\n",
    "                freq_list.append(j)\n",
    "        #print(freq_list)\n",
    "        for i in freq_list:\n",
    "            if i not in freq_uniq:\n",
    "                freq_uniq.append(i)\n",
    "        freq_uniq = sorted(freq_uniq, reverse=True)\n",
    "        #print(freq_uniq)\n",
    "        for i in freq_uniq:\n",
    "            for j in freq_list:\n",
    "                if i == j:\n",
    "                    self.bi_nc[i] += 1\n",
    "        ### End\n",
    "        \n",
    "        \n",
    "    def _calc_c_star_and_N(self):\n",
    "        ''' Calculate c_star and N. (page 65 of slides (lecture 5))\n",
    "        '''\n",
    "        \n",
    "        ### Start your code\n",
    "        \n",
    "        c_list = list(self.uni_nc.keys())\n",
    "        \n",
    "        for c in range(max(c_list)):\n",
    "            \n",
    "            try:\n",
    "            \n",
    "                self.uni_c_star[c] = (c + 1)*(self.uni_nc[c + 1]) / self.uni_nc[c]\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                self.uni_c_star[c] = (c + 1)*(self.uni_nc[c + 1])\n",
    "             \n",
    "            self.uni_N += c * self.uni_nc[c]\n",
    "            #print(self.uni_N, c, self.uni_nc[c])########\n",
    "            \n",
    "        c_list = list(self.bi_nc.keys())\n",
    "        \n",
    "        for c in range(max(c_list)):\n",
    "            \n",
    "            try:\n",
    "            \n",
    "                self.bi_c_star[c] = (c + 1)*(self.bi_nc[c + 1]) / self.bi_nc[c]\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                self.bi_c_star[c] = (c + 1)*(self.bi_nc[c + 1])\n",
    "             \n",
    "            self.bi_N += c*self.bi_nc[c]\n",
    "\n",
    "        ### End\n",
    "        \n",
    "        \n",
    "    def probability(self, w1, w2):\n",
    "        ''' Given two words, calculate the GT probability\n",
    "                p_GT = c_star / N, if c != 0\n",
    "                p_GT = N_1 / N, if c = 0\n",
    "                \n",
    "                p = p_GT(w1, w2) / p_GT(w1)\n",
    "                \n",
    "            Input\n",
    "                w1: the first word\n",
    "                w2: the second word\n",
    "                \n",
    "        '''\n",
    "        prob = 0.\n",
    "        \n",
    "        ### Start you code\n",
    "        \n",
    "        uni_c = self.uni_count[w1]\n",
    "        \n",
    "        bi_c = self.bi_count[w1][w2]\n",
    "        \n",
    "        if uni_c == 0 or uni_c == 1:\n",
    "            P_GT_w1 = self.uni_nc[1] / self.uni_N\n",
    "        else:\n",
    "            try:\n",
    "                P_GT_w1 = self.uni_c_star[uni_c] / self.uni_N\n",
    "            except:\n",
    "                P_GT_w1 = uni_c / self.uni_N\n",
    "                \n",
    "        if bi_c == 0 or bi_c == 1:\n",
    "            P_GT_w12 = self.bi_nc[bi_c] / self.bi_N\n",
    "        else:\n",
    "            try:\n",
    "                P_GT_w12 = self.bi_c_star[bi_c] / self.bi_N\n",
    "            except:\n",
    "                P_GT_w12 = bi_c / self.bi_N\n",
    "        \n",
    "        try:\n",
    "            prob = P_GT_w12 / P_GT_w1\n",
    "        except:\n",
    "            prob =  P_GT_w12 / (P_GT_w1 + 1/self.uni_N)\n",
    "        \n",
    "        ### End\n",
    "        \n",
    "        return prob\n",
    "\n",
    "    \n",
    "    def predict(self, w):\n",
    "        ''' Given a word, find a word with the highest probability\n",
    "            Input\n",
    "                w: a word\n",
    "                \n",
    "            Hint: utilize self.probability(w, w2) to find which w2 has the highest probability\n",
    "        '''\n",
    "        \n",
    "        w_next = None\n",
    "        \n",
    "        ### Start your code\n",
    "        \n",
    "        w_next_list = list(self.bi_count[w].keys())\n",
    "        \n",
    "        prob_list = []\n",
    "        \n",
    "        for w2 in w_next_list:\n",
    "            prob_list.append(self.probability(w, w2))\n",
    "            \n",
    "        w_next = w_next_list[prob_list.index(max(prob_list))]\n",
    "        \n",
    "        ### End\n",
    "        \n",
    "        return w_next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1d492f",
   "metadata": {
    "id": "a4c2d2c3"
   },
   "source": [
    "### 1.3 Implement Kneser-Ney smoothing (fill the code, 15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "22412ce1",
   "metadata": {
    "id": "0173537e"
   },
   "outputs": [],
   "source": [
    "class KneserNey(object):\n",
    "    \n",
    "    def __init__(self, bigram, d=0.75):\n",
    "        ''' Construction function of KneserNey.\n",
    "            Params:\n",
    "                uni_count: a dictionary with default value 0\n",
    "                bi_count: a dictionary that each value is a dictionary with default value 0\n",
    "                -----------------\n",
    "                num_bigram_types: page 73 of slides (lecture 5)\n",
    "                novel_continuation: \\{ w_{i-1}: c(w_{i-1}, w) \\}, page 73 of slides (lecture 5)\n",
    "                p_continuation: page 73 of slides (lecture 5)\n",
    "                novel_previous: \\{ w: c(w_{i-1}, w) \\}, page 75 of slides (lecture 5)\n",
    "                lam: page 75 of slides (lecture 5)\n",
    "                d: 0.75\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        self.uni_count = bigram.uni_count\n",
    "        self.bi_count = bigram.bi_count\n",
    "        \n",
    "        self.num_bigram_types = 0\n",
    "        self.novel_continuation = defaultdict(lambda: 0)\n",
    "        self.novel_previous = defaultdict(lambda: 0)\n",
    "        self.p_continuation = defaultdict(lambda: 0)\n",
    "        self.lam = defaultdict(lambda: 0)\n",
    "        \n",
    "        self.d = d\n",
    "        \n",
    "    \n",
    "    def fit(self, texts):\n",
    "        self._calc_num_bigram_types()\n",
    "        self._calc_novel_continuation_and_novel_previous()\n",
    "        self._calc_P_continuation()\n",
    "        self._calc_lambda()\n",
    "        \n",
    "    \n",
    "    def _calc_num_bigram_types(self):\n",
    "        ''' Calculate the number of bigram types, and store in self.num_bigram_types\n",
    "            page 73 of slides (lecture 5)\n",
    "            \n",
    "            Hint: you could utilize the bigram count (self.bi_count) which is obtained from Bigram model.\n",
    "        '''\n",
    "        \n",
    "        ### Start your code\n",
    "        \n",
    "        w2_list = list(self.uni_count.keys())\n",
    "        \n",
    "        w1_list = list(self.bi_count.keys())\n",
    "        \n",
    "        for w2 in w2_list:\n",
    "            \n",
    "            for w1 in w1_list:\n",
    "                \n",
    "                if self.bi_count[w1][w2] != 0:\n",
    "                    \n",
    "                    self.num_bigram_types += 1  \n",
    "                    \n",
    "        ### End\n",
    "      \n",
    "    \n",
    "    def _calc_novel_continuation_and_novel_previous(self):\n",
    "        ''' Calculate novel continuation, and novel previous, \n",
    "            and store them in self.novel_continuation and self.novel_previous\n",
    "            \n",
    "            novel_continuation = \\{ w_{i-1}: c(w_{i-1}, w) \\}, page 73 of slides (lecture 5)\n",
    "            novel_previous = \\{ w: c(w_{i-1}, w) \\}, page 75 of slides (lecture 5)\n",
    "            \n",
    "            Hint: you could utilize the bigram count (self.bi_count) which obtained from Bigram model.\n",
    "        '''\n",
    "        \n",
    "        ### Start your code\n",
    "        \n",
    "        w1_list = list(self.bi_count.keys())\n",
    "        \n",
    "        for w1 in w1_list:\n",
    "            self.novel_continuation[w1] = len(self.bi_count[w1])\n",
    "            \n",
    "        w2_list = list(self.uni_count.keys())\n",
    "        \n",
    "        for w2 in w2_list:\n",
    "            \n",
    "            for w1 in w1_list:\n",
    "                \n",
    "                if self.bi_count[w1][w2] != 0:\n",
    "                    \n",
    "                    self.novel_previous[w1] += 1\n",
    "    \n",
    "        ### End\n",
    "    \n",
    "    \n",
    "    def _calc_P_continuation(self):\n",
    "        ''' Calculate p continuation, and store in self.p_continuation.\n",
    "            page 73 of slides (lecture 5)\n",
    "            \n",
    "            Hint: you could utilize the novel continuation (self.novel_continuation).\n",
    "        '''\n",
    "        \n",
    "        ### Start your code \n",
    "        \n",
    "        w_list = list(self.novel_continuation.keys())\n",
    "        \n",
    "        for w in w_list:\n",
    "            \n",
    "            try:\n",
    "                self.p_continuation[w] = self.novel_continuation[w] / self.num_bigram_types\n",
    "                \n",
    "            except:\n",
    "                self.p_continuation[w] = self.novel_continuation[w]\n",
    "        \n",
    "        ### End\n",
    "    \n",
    "    \n",
    "    def _calc_lambda(self):\n",
    "        ''' Calculate lambda, and store in self.lam.\n",
    "            page 75 of slides (lecture 5)\n",
    "            \n",
    "            Hint: you could utilize the novel previous (self.novel_previous) and unigram (self.uni_count).\n",
    "        '''\n",
    "        \n",
    "        ### Start your code\n",
    "        \n",
    "        w1_list = list(self.bi_count.keys())\n",
    "        \n",
    "        for w1 in w1_list:\n",
    "            \n",
    "            try:\n",
    "                self.lam[w1] = (self.d / self.uni_count[w1]) * (len(self.bi_count[w1]))\n",
    "            except:\n",
    "                self.lam[w1] = (self.d) * (len(self.bi_count[w1]))\n",
    "            \n",
    "        ### End\n",
    "        \n",
    "        \n",
    "    def probability(self, w1, w2):\n",
    "        ''' Given two words, calculate the KN probability\n",
    "            Page 74 of slides (lecture 5)\n",
    "                \n",
    "            Input\n",
    "                w1: the first word\n",
    "                w2: the second word\n",
    "        '''\n",
    "        \n",
    "        prob = 0.\n",
    "        \n",
    "        # Start your code\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            prob = (max(self.bi_count[w1][w2] - self.d, 0)/self.uni_count(w1)) + (self.lam[w1] * self.p_continuation[w2])\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            prob = (max(self.bi_count[w1][w2] - self.d, 0)) + (self.lam[w1] * self.p_continuation[w2])\n",
    "        \n",
    "        # End\n",
    "            \n",
    "        return prob\n",
    "    \n",
    "    \n",
    "    def predict(self, w):\n",
    "        ''' Given a word, find a word with the highest probability\n",
    "            Input\n",
    "                w: a word\n",
    "                \n",
    "            Hint: utilize self.probability(w, w2) to find which w2 has the highest probability\n",
    "        '''\n",
    "        \n",
    "        pred = ''\n",
    "        \n",
    "        ### Start your code\n",
    "        \n",
    "        w_next_list = list(self.bi_count[w].keys())\n",
    "        \n",
    "        prob_list = []\n",
    "        \n",
    "        for w2 in w_next_list:\n",
    "            prob_list.append(self.probability(w, w2))\n",
    "        \n",
    "        pred = w_next_list[prob_list.index(max(prob_list))]\n",
    "                \n",
    "        ### End\n",
    "                \n",
    "        return pred\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167c87c",
   "metadata": {
    "id": "4d622210"
   },
   "source": [
    "### 1.4 Implement Perplexity (fill the code, 10 point)\n",
    "**Hint:** Multiplication of probabilities may lead to an overflow problem. One trick is to move the computation to the logarithm space. Therefore, you could use summation instead of multiplication to calculate perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "1ec0ccbe",
   "metadata": {
    "id": "651d873e"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def perplexity(model, texts):\n",
    "    ''' Calculate the perplexity score.\n",
    "        Inputs\n",
    "            model: the model you want to evaluate (BiGram, GoodTuring, or KneserNey)\n",
    "            texts: a list of validation text\n",
    "        Output\n",
    "            perp: the perplexity of the model on texts\n",
    "    '''\n",
    "    perp = 1.\n",
    "    \n",
    "    ### Start your code\n",
    "    flag = []\n",
    "    btoks = []\n",
    "    prob_len = 0\n",
    "    prob_sum = 0\n",
    "    for sen in texts:\n",
    "        btoks.append(tokenize(Preprocesser().apply(sen[1:])))\n",
    "    for sen in btoks:\n",
    "        for i in range(len(sen) - 1):\n",
    "            w = (sen[i],sen[i+1])\n",
    "            if w not in flag:\n",
    "                flag.append(w)\n",
    "                y = model.probability(w[0],w[1])\n",
    "                if y == 0:\n",
    "                    y = 1E-1\n",
    "                prob_sum += math.log(y)\n",
    "                prob_len += 1\n",
    "                \n",
    "    perp = math.exp((-1 / prob_len) * prob_sum)\n",
    "\n",
    "    ### End\n",
    "    \n",
    "    return perp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46deaf60",
   "metadata": {
    "id": "1ae9b9bc"
   },
   "source": [
    "### 1.5 Calculate the perplexity of three models\n",
    "\n",
    "Run the following cell to obtian the perplexity of BiGram, Good Turing, and Kneser-Ney.\n",
    "\n",
    "**Note that, the perlexity should be less than 100.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "1c398a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f93c1a2c9f242c2b163f5620ae7c3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7059f4db23eb41a2b94d78309a92d2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19506 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3f1812c7c84a11800d8783ee72e412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3346fb73bec443fb48136c63578ee49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity of Bigram is: 18.6332\n"
     ]
    }
   ],
   "source": [
    "# Train Bigram\n",
    "bigram = BiGram()\n",
    "bigram.fit(train_texts[:1000])\n",
    "\n",
    "# Perplexity\n",
    "bigram_perplexity = perplexity(bigram, valid_texts[:10])\n",
    "print(f'The perplexity of Bigram is: {bigram_perplexity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "4259c0e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 152,
     "referenced_widgets": [
      "9a53da36e76a4c078ec997f7ecb19c53",
      "96df479f4bce49a6ad50823ca13c7a8a",
      "1f3cad8f4790440991d8689a6901092b",
      "7f5cad4515454ac1b3cf13bafe2be8b7",
      "dcf79d8ac613425fa5680359fcd55e52",
      "3348deeabd834cc8af78d259c5d264eb",
      "eef62927dca744b0b0ac405a69077e1d",
      "661ea4ef6e4c46e4930a9fe6622e15b6",
      "76435fd43d15403aa6ae09c170d08bff",
      "5eac3a9da9574e898c0c10b93577b244",
      "1e5cbadd09154cae8aa3ed9cffccaecf",
      "c63c7845afb448adb5e2b791aa6711f2",
      "b86c1938fbf54e1f9ec838d22ac8e686",
      "3f98bb7355c8445c8e6f533c010723df",
      "f7105aa135ab48fb8ba43a3b6df554a8",
      "3545d285dd56410eb867b6bddd64bbfb",
      "1c400992df144367acc8f1684428f24e",
      "554d18a1a4d846b184aa00cbc93a5578",
      "93d68d9d5ae64d3cb21e70b9e60dad35",
      "a83a2f6476014b699354aeec51081856",
      "589fdc916f904eb8a2c14cde025eee02",
      "798c1eca83ef4409ad5cf05ead9a55c0"
     ]
    },
    "id": "5ffee5d5",
    "outputId": "ff739636-703b-40dc-b185-dbfd0ce77d40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity of Good Turing is: 0.1797\n"
     ]
    }
   ],
   "source": [
    "# Train Good Turing\n",
    "gt = GoodTuring(bigram)\n",
    "gt.fit(train_texts[:1000])\n",
    "\n",
    "# Perplexity\n",
    "gt_perplexity = perplexity(gt, valid_texts[:10])\n",
    "print(f'The perplexity of Good Turing is: {gt_perplexity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "a814a26e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "b00b6b54679a43b3bdc1259ad6f0e8b0",
      "d05c534b93d24537924364b5e0f90e41",
      "eeb84b4f6bea45a6bcadd12e6a68ee83",
      "aebb9ebcf3f642d1ab1cbdc27dc4765c",
      "da209ecaa8af40e6b771ec773a4596e4",
      "f7f1f75e05d34717ba63436a403541d4",
      "9a8be20f7afd48a38aaaac982a3e020b",
      "7e51e710fe314164bd358efa9f7c553e",
      "08888abc179e4f4db80b340adf3cefc4",
      "546564a20a2243c1a901562e6e16357e",
      "82188772d1a64ddfbf2b18049e8991f0"
     ]
    },
    "id": "28e36676",
    "outputId": "0956a545-979e-42c2-8b0f-91bc0dc6bfa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity of Kneser-Ney is: 0.0205\n"
     ]
    }
   ],
   "source": [
    "# For Kneser-Ney\n",
    "kn = KneserNey(bigram, d=0.75)\n",
    "kn.fit(train_texts[:1000])\n",
    "\n",
    "# Perplexity\n",
    "kn_perplexity = perplexity(kn, valid_texts[:10])\n",
    "print(f'The perplexity of Kneser-Ney is: {kn_perplexity:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4e6179",
   "metadata": {
    "id": "a6438a7d"
   },
   "source": [
    "### 1.6 Use N-gram model make predictions\n",
    "\n",
    "Run the following cells to see how your models work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a7643e",
   "metadata": {},
   "source": [
    "#### 1.6.1 Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "fe162122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ==> but <unk> <unk> an attorney for the nfl says his ___, prediction: campaign\n",
      "1 ==> with the european community set to remove its internal trade ___, prediction: deficit\n",
      "2 ==> i think my line has been very consistent mrs. hills ___, prediction: said\n",
      "3 ==> the company is already working on its own programming in ___, prediction: the\n",
      "4 ==> in addition officials at the fed and in the bush ___, prediction: has\n",
      "5 ==> once known as national <unk> & chemical corp. the company ___, prediction: said\n",
      "6 ==> a spokesman for rep. edward j. markey <unk> who heads ___, prediction: is\n",
      "7 ==> the consensus view expects a N N increase in the ___, prediction: us\n",
      "8 ==> treasurys opened lower reacting <unk> to news that the producer ___, prediction: and\n",
      "9 ==> <unk> products inc. said a u.s. district court in boston ___, prediction: s\n",
      "10 ==> as the dow average ground to its final N loss ___, prediction: of\n",
      "11 ==> for his sixth novel mr. <unk> tried to <unk> the ___, prediction: us\n",
      "12 ==> he like justice <unk> considers <unk> highly important for the ___, prediction: us\n",
      "13 ==> this growth puts houston in the top five <unk> areas ___, prediction: of\n",
      "14 ==> things have gone too far for the government to stop ___, prediction: privately\n",
      "15 ==> and time 's paid circulation according to audit bureau of ___, prediction: the\n",
      "16 ==> a spokesman for the new york-based food and tobacco giant ___, prediction: group\n",
      "17 ==> mr. <unk> said the bank 's experience with <unk> debt ___, prediction: obligations\n",
      "18 ==> in any case <unk> operators have reason to fear any ___, prediction: questionable\n",
      "19 ==> this is the latest <unk> of the capacity of the ___, prediction: us\n",
      "20 ==> it has plunged N N since july to around N ___, prediction: n\n",
      "21 ==> that means two plants one in <unk> ontario and the ___, prediction: us\n",
      "22 ==> many money managers and some traders had already left their ___, prediction: own\n",
      "23 ==> mr. <unk> however worries that the market could go down ___, prediction: n\n",
      "24 ==> on the otc market first executive a big buyer of ___, prediction: the\n",
      "25 ==> the strike by customs officers tax collectors treasury workers and ___, prediction: the\n",
      "26 ==> and concern about official actions aimed at takeovers then by ___, prediction: the\n",
      "27 ==> ideal basic industries inc. said its directors reached an agreement ___, prediction: with\n",
      "28 ==> toy makers complain that electricity in <unk> has been provided ___, prediction: by\n",
      "29 ==> examples include <unk> whose agreement to be acquired for $ ___, prediction: the\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sampled_texts = random.sample(test_texts, 30)\n",
    "for i, text in enumerate(sampled_texts):\n",
    "    clean_text = preprocesser.apply(text)\n",
    "    tokens = tokenize(clean_text)\n",
    "    pred = bigram.predict(tokens[-1])\n",
    "    print(f'{i} ==> {text.strip()}, prediction: {pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8646cf3",
   "metadata": {},
   "source": [
    "#### 1.6.2 Good Turing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "3e787161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ==> it seems to me that this is the <unk> that ___, prediction: hung\n",
      "1 ==> messrs. <unk> and <unk> are directors of <unk> which has ___, prediction: recorded\n",
      "2 ==> <unk> hot dry weather across large portions of the great ___, prediction: purpose\n",
      "3 ==> the latter typically is the humor of the <unk> and ___, prediction: boston\n",
      "4 ==> the ginnie mae november N N issue ended at N ___, prediction: men\n",
      "5 ==> these are n't mature assets but they have the potential ___, prediction: too\n",
      "6 ==> trinity industries inc. said it reached a preliminary agreement to ___, prediction: t\n",
      "7 ==> those are not <unk> questions and the label national service ___, prediction: parts\n",
      "8 ==> half of them are really scared and want to sell ___, prediction: conventional\n",
      "9 ==> we would obviously be upset if those kinds of services ___, prediction: plans\n",
      "10 ==> mario <unk> for instance holds cash positions well above N ___, prediction: men\n",
      "11 ==> mr. greenberg got out just before the N crash and ___, prediction: boston\n",
      "12 ==> stock prices would still have to go down some additional ___, prediction: refund\n",
      "13 ==> the networks still are <unk> in their authority over what ___, prediction: matters\n",
      "14 ==> a <unk> spokesman said the products contribute about a third ___, prediction: year\n",
      "15 ==> he adds the junk market has <unk> some trouble and ___, prediction: boston\n",
      "16 ==> labor gets N pence N cents for every N about ___, prediction: years\n",
      "17 ==> at usa today ad pages totaled N for the quarter ___, prediction: agrees\n",
      "18 ==> still even that modest increase is good news for a ___, prediction: striking\n",
      "19 ==> we told the little guy it could only happen once ___, prediction: it\n",
      "20 ==> there was n't a lot of volume because it was ___, prediction: far\n",
      "21 ==> the plunge in stock prices is happening at a time ___, prediction: s\n",
      "22 ==> it will continue to trade on the international stock exchange ___, prediction: were\n",
      "23 ==> shortly before the visit mr. boesky and drexel <unk> had ___, prediction: space\n",
      "24 ==> a spokesman for the new york-based food and tobacco giant ___, prediction: montedison\n",
      "25 ==> the <unk> is believed to be the first such cross-border ___, prediction: movement\n",
      "26 ==> direction to the u.s. coast guard to collect $ N ___, prediction: men\n",
      "27 ==> the company said a portion of the $ N million ___, prediction: so\n",
      "28 ==> we 've had two more years of significant accumulation of ___, prediction: consolidated\n",
      "29 ==> the soviet union reported that thousands of tons of goods ___, prediction: by\n"
     ]
    }
   ],
   "source": [
    "sampled_texts = random.sample(test_texts, 30)\n",
    "for i, text in enumerate(sampled_texts):\n",
    "    clean_text = preprocesser.apply(text)\n",
    "    tokens = tokenize(clean_text)\n",
    "    pred = gt.predict(tokens[-1])\n",
    "    print(f'{i} ==> {text.strip()}, prediction: {pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8ddd88",
   "metadata": {},
   "source": [
    "#### 1.6.3 Kneser-Ney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "552bcfa3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e72a4613",
    "outputId": "145ecc65-b652-4a99-d4d7-da89a4212be9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ==> after <unk> for about N minutes the s&p index tumbled ___, prediction: n\n",
      "1 ==> manufacturers say there is no immediate substitute for southern china ___, prediction: thailand\n",
      "2 ==> thus europe has begun the recent crusade to produce more ___, prediction: than\n",
      "3 ==> the dow 's decline was second in point terms only ___, prediction: the\n",
      "4 ==> greece 's <unk> relations with the u.s. need attention soon ___, prediction: will\n",
      "5 ==> a spokesman for the company said the verdict is thought ___, prediction: to\n",
      "6 ==> but we came into friday with a conservative portfolio so ___, prediction: far\n",
      "7 ==> japanese stocks dropped early monday but by late morning were ___, prediction: nt\n",
      "8 ==> stock funds have averaged a staggering gain of N N ___, prediction: n\n",
      "9 ==> he said he believes gm has plans to keep building ___, prediction: activity\n",
      "10 ==> the <unk> has faced heightened competition from rival time magazine ___, prediction: and\n",
      "11 ==> this time i do n't think we 'll get a ___, prediction: new\n",
      "12 ==> it also marks p&g 's growing concern that its japanese ___, prediction: investors\n",
      "13 ==> if the reactions of executives gathered saturday at hot springs ___, prediction: colo\n",
      "14 ==> after a supply crunch caused prices to rise N N ___, prediction: n\n"
     ]
    }
   ],
   "source": [
    "sampled_texts = random.sample(test_texts, 15)\n",
    "for i, text in enumerate(sampled_texts):\n",
    "    clean_text = preprocesser.apply(text)\n",
    "    tokens = tokenize(clean_text)\n",
    "    pred = kn.predict(tokens[-1])\n",
    "    print(f'{i} ==> {text.strip()}, prediction: {pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3d3797",
   "metadata": {
    "id": "6d1cf523"
   },
   "source": [
    "## 2. RNN (50 points)\n",
    "In this section, you are required to implement an RNN-based language model. **Libraries are allowed in this section, such as PyTorch or TensorFlow**. And, of course, you could implement the model from scratch which will get extra credits. \n",
    "\n",
    "I divided the whole process into several steps.\n",
    "1. Initialize parameters\n",
    "2. Prepare Data\n",
    "3. Implement the model\n",
    "4. Train your model\n",
    "5. Evaluate your model\n",
    "\n",
    "Please note that you could change those steps by your needs. As long as you correctly implement the model and have reasonable results you will get full points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f31ae4d",
   "metadata": {
    "id": "b696ab8c"
   },
   "source": [
    "### 2.1 Initialize parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "194ff8d9",
   "metadata": {
    "id": "c11c8846"
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#                                                     #\n",
    "#        Change the default values accordingly        #\n",
    "#                                                     #\n",
    "#######################################################\n",
    "\n",
    "learning_rate = 1E-6\n",
    "batch_size = 1\n",
    "hidden_size = 30\n",
    "embedding_size = 50\n",
    "num_epochs = 50\n",
    "window_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e69e65",
   "metadata": {
    "id": "b96cd8d0"
   },
   "source": [
    "### 2.2 Data preparation (Fill the code: 5 points)\n",
    "\n",
    "Here is what do you might need to do in this section:\n",
    "1. Build a vocabulary.\n",
    "2. Prepare the training data.\n",
    "3. Prepare the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "dc15fad4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "db92112fd1404654a3f11dec95a79378",
      "634379b2174944c6a2527d43d6fb21ca",
      "6f013dd9434e4a019af0ffcaf5bc1194",
      "73887cb869e94589b4e5b1b691b6f937",
      "e6f545c0008e45ff95ea610c86b10987",
      "ceb86bd353e44e358ade1af7dd367b1a",
      "f4927eb77cee4fc69c897fb3911f5793",
      "8e5a920068fd48b6b7af469c6e43b2f4",
      "28977ef615ed4798abeed10e8f8d3677",
      "e94ddfd39d1d4e80937eb1c7257b4526",
      "6be04f4c233d468595cad6b45aff8040"
     ]
    },
    "id": "0c6d3d76",
    "outputId": "0a9d3026-a930-4791-dc39-7421f90f8d74"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4e22c0a78e41f18a68a38bbefa5b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bccb293c214b24a286fa6d5d405842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe268e7804446b484f62e1c5d5d10a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8810 10000 1000\n"
     ]
    }
   ],
   "source": [
    "### Start your code\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "toks = []\n",
    "vocab = []\n",
    "txt = train_texts[:11000]\n",
    "\n",
    "for sen in tqdm(txt):\n",
    "    toks.append(tokenize(Preprocesser().apply(sen[1:])))\n",
    "    for word in tokenize(Preprocesser().apply(sen[1:])):\n",
    "        vocab.append(word)\n",
    "        \n",
    "vocab = np.unique(np.array(vocab))\n",
    "embeds = Word2Vec(sentences=toks, vector_size=embedding_size, window=window_size, min_count=1, workers=4)\n",
    "embeds.train(vocab, epochs=50, total_examples=1)\n",
    "vocab_vectors = embeds.wv\n",
    "print(vocab_vectors['the'].shape)\n",
    "\n",
    "toks = []\n",
    "txt = train_texts[:10000]\n",
    "for sen in tqdm(txt):\n",
    "    toks.append(tokenize(Preprocesser().apply(sen[1:])))\n",
    "    \n",
    "data_train = toks\n",
    "\n",
    "toks = []\n",
    "txt = train_texts[10000:11000]\n",
    "for sen in tqdm(txt):\n",
    "    toks.append(tokenize(Preprocesser().apply(sen[1:])))\n",
    "    \n",
    "data_val = toks\n",
    "\n",
    "print(len(vocab), len(data_train), len(data_val))\n",
    "\n",
    "### End\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14654a35",
   "metadata": {
    "id": "2f3832aa"
   },
   "source": [
    "### 2.3 Build your model (Fill the code: 10 points)\n",
    "\n",
    "\n",
    "Here is what do you might need to do in this section:\n",
    "1. Create a model.\n",
    "2. Add an embedding layer as the first layer.\n",
    "3. Add a RNN cell (GRU or LSTM) as the next layer.\n",
    "4. Add a output layer.\n",
    "5. Given a sequence words, for each word, predict the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "18c148df",
   "metadata": {
    "id": "38b3fede"
   },
   "outputs": [],
   "source": [
    "### Start your code\n",
    "class Embed():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.vectorize = vocab_vectors\n",
    "        \n",
    "    def transform(self, data):\n",
    "            \n",
    "        y = self.vectorize[data]\n",
    "            \n",
    "        y = np.expand_dims(y, axis=0)\n",
    "        \n",
    "        y = np.expand_dims(y, axis=0)\n",
    "        \n",
    "        y = torch.from_numpy(y)\n",
    "        \n",
    "        return y\n",
    "\n",
    "class my_RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = Embed()\n",
    "        self.rnn_cell = nn.LSTM(input_size = input_size, hidden_size = hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, input_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y = self.embed.transform(x) #shape -> (#batches,#sequence, 200)\n",
    "        #print(y.shape)\n",
    "        y = self.rnn_cell(y)\n",
    "        #print(y[0].shape)\n",
    "        y = self.out(y[0]) #shape -> (200)\n",
    "        \n",
    "        return y\n",
    "\n",
    "### End\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbef8bb",
   "metadata": {
    "id": "a0cbf03a"
   },
   "source": [
    "### 2.4 Setup the training step and train the model (Fill the code: 10 points)\n",
    "Based on your implementation, setup your training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "cef66f94",
   "metadata": {
    "id": "6cf0bd2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "      Loss: 0.23967627081432222\n",
      "Epoch 1\n",
      "      Loss: 0.1767054773995482\n",
      "Epoch 2\n",
      "      Loss: 0.1692898088391746\n",
      "Epoch 3\n",
      "      Loss: 0.1650633037403473\n",
      "Epoch 4\n",
      "      Loss: 0.1624382092013053\n",
      "Epoch 5\n",
      "      Loss: 0.1606972660984728\n",
      "Epoch 6\n",
      "      Loss: 0.1594889725185042\n",
      "Epoch 7\n",
      "      Loss: 0.1586202569372565\n",
      "Epoch 8\n",
      "      Loss: 0.157973217227667\n",
      "Epoch 9\n",
      "      Loss: 0.15747403505715404\n",
      "Epoch 10\n",
      "      Loss: 0.15707689962288984\n",
      "Epoch 11\n",
      "      Loss: 0.1567532736824991\n",
      "Epoch 12\n",
      "      Loss: 0.1564848357926695\n",
      "Epoch 13\n",
      "      Loss: 0.15625917664181574\n",
      "Epoch 14\n",
      "      Loss: 0.1560673479401663\n",
      "Epoch 15\n",
      "      Loss: 0.15590255272107295\n",
      "Epoch 16\n",
      "      Loss: 0.15575947175699933\n",
      "Epoch 17\n",
      "      Loss: 0.15563387919643015\n",
      "Epoch 18\n",
      "      Loss: 0.1555223963673466\n",
      "Epoch 19\n",
      "      Loss: 0.15542233078253714\n",
      "Epoch 20\n",
      "      Loss: 0.15533154621586803\n",
      "Epoch 21\n",
      "      Loss: 0.1552483478312209\n",
      "Epoch 22\n",
      "      Loss: 0.15517138646061393\n",
      "Epoch 23\n",
      "      Loss: 0.15509959863002218\n",
      "Epoch 24\n",
      "      Loss: 0.15503212637408426\n",
      "Epoch 25\n",
      "      Loss: 0.1549682919332468\n",
      "Epoch 26\n",
      "      Loss: 0.15490754496160639\n",
      "Epoch 27\n",
      "      Loss: 0.1548494307905187\n",
      "Epoch 28\n",
      "      Loss: 0.15479358002180277\n",
      "Epoch 29\n",
      "      Loss: 0.15473968745514177\n",
      "Epoch 30\n",
      "      Loss: 0.15468749906626067\n",
      "Epoch 31\n",
      "      Loss: 0.15463679941938852\n",
      "Epoch 32\n",
      "      Loss: 0.1545874027288274\n",
      "Epoch 33\n",
      "      Loss: 0.15453915076046507\n",
      "Epoch 34\n",
      "      Loss: 0.15449191400907286\n",
      "Epoch 35\n",
      "      Loss: 0.15444557497692168\n",
      "Epoch 36\n",
      "      Loss: 0.15440003021256843\n",
      "Epoch 37\n",
      "      Loss: 0.1543551926281526\n",
      "Epoch 38\n",
      "      Loss: 0.15431098256312747\n",
      "Epoch 39\n",
      "      Loss: 0.1542673310834399\n",
      "Epoch 40\n",
      "      Loss: 0.15422418082002023\n",
      "Epoch 41\n",
      "      Loss: 0.15418147702646098\n",
      "Epoch 42\n",
      "      Loss: 0.1541391724691814\n",
      "Epoch 43\n",
      "      Loss: 0.15409722606266657\n",
      "Epoch 44\n",
      "      Loss: 0.1540556081973157\n",
      "Epoch 45\n",
      "      Loss: 0.15401429270611677\n",
      "Epoch 46\n",
      "      Loss: 0.15397325710751214\n",
      "Epoch 47\n",
      "      Loss: 0.15393248872570958\n",
      "Epoch 48\n",
      "      Loss: 0.15389197124445161\n",
      "Epoch 49\n",
      "      Loss: 0.15385170553956312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "my_RNN(\n",
       "  (rnn_cell): LSTM(50, 30, batch_first=True)\n",
       "  (out): Linear(in_features=30, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Start your code\n",
    "\n",
    "model = my_RNN(embedding_size, hidden_size)\n",
    "\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "    \n",
    "    loss_list = []\n",
    "    \n",
    "    print('Epoch', ep)\n",
    "    \n",
    "    for sen in data_train:\n",
    "        \n",
    "        for i in range(len(sen) - 1):\n",
    "    \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            y = model.forward(sen[i])\n",
    "\n",
    "            L = loss(y, model.embed.transform(sen[i + 1]))\n",
    "\n",
    "            L.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_list.append(float(L))\n",
    "            \n",
    "    print('      Loss:', sum(loss_list) / len(loss_list))\n",
    "\n",
    "model.eval()\n",
    "          \n",
    "### End\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa768e92",
   "metadata": {
    "id": "9c9ebdc6"
   },
   "source": [
    "### 2.5 Evaluate the model (15 points)\n",
    "Calculate the model's perplexity on the valid set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dd647c",
   "metadata": {
    "id": "f9677797"
   },
   "source": [
    "#### 2.5.1 Deliverable (5 points)\n",
    "Prove\n",
    "<center>$perplexity = exp(\\frac{total\\ loss}{number\\ of\\ predictions})$\n",
    "    \n",
    "*You can either list the steps in the notebook or submit a pdf with all the steps in the submission.*\n",
    "    \n",
    "#### Solution:\n",
    "    \n",
    "    We know the formula for PP as N_root(pi_i=1_N(1/Pi))\n",
    "    Taking the exponential and log of this equation gives e^(1/N * (sum_i=1_N(log(1/Pi)))\n",
    "    expanding the contents of log gives -log(Pi) = L_i\n",
    "    Thus sum_L_i = L_total\n",
    "    And hence the equation for PP = e^(L_total / N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc301831",
   "metadata": {
    "id": "JqtbFu_YHTu1"
   },
   "source": [
    "#### 2.5.2 Implement the algorithm to calculate the perplexity of the model. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "e37cd068",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "033f5d5d7d254e0eaa9e8248a922cd24",
      "777e888395634af98a54350e9afd3173",
      "23bf828777d6427ca881362636957c1f",
      "1d29f3408a014f69a7e5d422012af3df",
      "79f0039ff69d442fb308d2572e45568e",
      "d1c4dda64d4d4938ac0592eede0af27a",
      "486338a06f9740ddae037dc655a7d18a",
      "5835dc4965724bb29c0f844c1de605a7",
      "dcf4e8ce928244b8b4c07ffe0225fffc",
      "e469615a3ad143318cec11ed6ea82346",
      "73800733b6e549f08c2dc81b292520c4"
     ]
    },
    "id": "20d16e69",
    "outputId": "a04d4c92-9172-414a-e177-2f2881458034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity of of RNN based model is: 1.1616\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "perp = 0.\n",
    "\n",
    "### Start your code\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "pred_len = 0\n",
    "    \n",
    "for sen in data_val:\n",
    "        \n",
    "    for i in range(len(sen) - 1):\n",
    "    \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        y = model.forward(sen[i])\n",
    "\n",
    "        L = loss(y, model.embed.transform(sen[i + 1]))\n",
    "\n",
    "        loss_list.append(float(L))\n",
    "        \n",
    "        pred_len += 1\n",
    "            \n",
    "loss = sum(loss_list) / len(loss_list)\n",
    "\n",
    "perp = math.exp(loss)\n",
    "\n",
    "### End\n",
    "\n",
    "print(f'The perplexity of of RNN based model is: {perp:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ceae39",
   "metadata": {
    "id": "e30f87fc"
   },
   "source": [
    "### 2.6 Use RNN language modeling make predictions (10 points)\n",
    "Print the predictions of next words using the RNN model for the same 30 lines of input.txt as in section 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "9b080619",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 987
    },
    "id": "d9659bee",
    "outputId": "9ef30f12-d20e-4191-e924-9872bd87b551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ==> in response to <unk> domestic supplies agriculture secretary <unk> <unk> ___, prediction: outside\n",
      "1 ==> another half million <unk> went for a <unk> of <unk> ___, prediction: an\n",
      "2 ==> companies with which <unk> has had talks about a possible ___, prediction: card\n",
      "3 ==> financial corp. of santa barbara filed suit against former stock ___, prediction: federal\n",
      "4 ==> if dow industrials fall N points trading on the big ___, prediction: texas\n",
      "5 ==> last summer mr. bush moved the administration in the direction ___, prediction: against\n",
      "6 ==> it settled with a loss of N cents at $ ___, prediction: eight\n",
      "7 ==> obviously ibm can give bigger discounts to users immediately said ___, prediction: hills\n",
      "8 ==> one reason is mounting competition from new japanese car plants ___, prediction: transportation\n",
      "9 ==> but i think the kind of congressional investigation that has ___, prediction: any\n",
      "10 ==> harvard law school professor laurence tribe says there is a ___, prediction: day\n",
      "11 ==> today he <unk> exports and business investment spending may be ___, prediction: sold\n",
      "12 ==> to take full advantage of the financial opportunities in this ___, prediction: series\n",
      "13 ==> the executive said any buy-out would be led by the ___, prediction: major\n",
      "14 ==> <unk> the risk of such prosecution a court may order ___, prediction: transportation\n",
      "15 ==> i see this as a reaction to the whole junk ___, prediction: every\n",
      "16 ==> the administration has sent out confusing signals about its response ___, prediction: against\n",
      "17 ==> people of all ages and all classes should be encouraged ___, prediction: against\n",
      "18 ==> if it does n't yield on these matters and eventually ___, prediction: fixed\n",
      "19 ==> the company said the improvement is related to additional <unk> ___, prediction: transportation\n",
      "20 ==> both paribas and <unk> have been increasing their stakes in ___, prediction: control\n",
      "21 ==> he did repeat those nice <unk> several times as an ___, prediction: through\n",
      "22 ==> the crash of N was followed by a substantial recovery ___, prediction: against\n",
      "23 ==> while the earnings picture <unk> observers say the major forces ___, prediction: transportation\n",
      "24 ==> tandem said it expects to report revenue of about $ ___, prediction: valued\n",
      "25 ==> so it seems that mr. <unk> and his communist <unk> ___, prediction: fixed\n",
      "26 ==> many fund managers argue that now 's the time to ___, prediction: come\n",
      "27 ==> that became clear last week with the disclosure that national ___, prediction: owns\n",
      "28 ==> japan has been shipping steel to total about N N ___, prediction: trillion\n",
      "29 ==> if the economy continues to expand by N N a ___, prediction: day\n"
     ]
    }
   ],
   "source": [
    "### Start your code\n",
    "\n",
    "import random\n",
    "\n",
    "sampled_texts = random.sample(test_texts, 30)\n",
    "for i, text in enumerate(sampled_texts):\n",
    "    clean_text = preprocesser.apply(text)\n",
    "    tokens = tokenize(clean_text)\n",
    "    pred = model.forward(tokens[-1]).to('cpu').detach().numpy().squeeze()\n",
    "    pred = vocab_vectors.most_similar(positive=[pred], topn=10)[0][0]\n",
    "    print(f'{i} ==> {text.strip()}, prediction: {pred}')\n",
    "\n",
    "### End\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CS584A_21F_Assignment3_sol.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "033f5d5d7d254e0eaa9e8248a922cd24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_23bf828777d6427ca881362636957c1f",
       "IPY_MODEL_1d29f3408a014f69a7e5d422012af3df",
       "IPY_MODEL_79f0039ff69d442fb308d2572e45568e"
      ],
      "layout": "IPY_MODEL_777e888395634af98a54350e9afd3173"
     }
    },
    "04b88d3a05db465097d3b6d132b9d4d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08888abc179e4f4db80b340adf3cefc4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0afd68d6cc3e452b9995c16b45498e0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1282ffc696e94bde9d464c086bf56a9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c400992df144367acc8f1684428f24e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d29f3408a014f69a7e5d422012af3df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcf4e8ce928244b8b4c07ffe0225fffc",
      "max": 72,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5835dc4965724bb29c0f844c1de605a7",
      "value": 72
     }
    },
    "1e5cbadd09154cae8aa3ed9cffccaecf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f3cad8f4790440991d8689a6901092b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eef62927dca744b0b0ac405a69077e1d",
      "placeholder": "​",
      "style": "IPY_MODEL_3348deeabd834cc8af78d259c5d264eb",
      "value": "good turing: 100%"
     }
    },
    "22fce55c7fac47be8151cf2aabb19c7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "232b015d2d50456199173cf15c705f76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9fa143b50b4a4071966a75797331120c",
       "IPY_MODEL_4fc66537350d420b98eeda74530956e8",
       "IPY_MODEL_b508585491914913af1e97442d173c19"
      ],
      "layout": "IPY_MODEL_ec79cb6402fb48209b04cf141b682e02"
     }
    },
    "23bf828777d6427ca881362636957c1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_486338a06f9740ddae037dc655a7d18a",
      "placeholder": "​",
      "style": "IPY_MODEL_d1c4dda64d4d4938ac0592eede0af27a",
      "value": "Evaluating: 100%"
     }
    },
    "28977ef615ed4798abeed10e8f8d3677": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3348deeabd834cc8af78d259c5d264eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3545d285dd56410eb867b6bddd64bbfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_798c1eca83ef4409ad5cf05ead9a55c0",
      "placeholder": "​",
      "style": "IPY_MODEL_589fdc916f904eb8a2c14cde025eee02",
      "value": " 3370/3370 [00:22&lt;00:00, 148.03it/s]"
     }
    },
    "366a68482f1b4c9aace014294204a3d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f98bb7355c8445c8e6f533c010723df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_554d18a1a4d846b184aa00cbc93a5578",
      "placeholder": "​",
      "style": "IPY_MODEL_1c400992df144367acc8f1684428f24e",
      "value": "perplexity: 100%"
     }
    },
    "43ee7b41140e428ba38e051926a185e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "486338a06f9740ddae037dc655a7d18a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fc66537350d420b98eeda74530956e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22fce55c7fac47be8151cf2aabb19c7e",
      "max": 920,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_43ee7b41140e428ba38e051926a185e5",
      "value": 27
     }
    },
    "546564a20a2243c1a901562e6e16357e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "554d18a1a4d846b184aa00cbc93a5578": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5835dc4965724bb29c0f844c1de605a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "589fdc916f904eb8a2c14cde025eee02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5eac3a9da9574e898c0c10b93577b244": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "61d7f90ab5d140c48dc3dd199b6acf75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "634379b2174944c6a2527d43d6fb21ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "661ea4ef6e4c46e4930a9fe6622e15b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6be04f4c233d468595cad6b45aff8040": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f013dd9434e4a019af0ffcaf5bc1194": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4927eb77cee4fc69c897fb3911f5793",
      "placeholder": "​",
      "style": "IPY_MODEL_ceb86bd353e44e358ade1af7dd367b1a",
      "value": "100%"
     }
    },
    "728ff942c62e4316bee3712f83be0d4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73800733b6e549f08c2dc81b292520c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73887cb869e94589b4e5b1b691b6f937": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28977ef615ed4798abeed10e8f8d3677",
      "max": 42068,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e5a920068fd48b6b7af469c6e43b2f4",
      "value": 42068
     }
    },
    "75ad4c14843d41a18298b4580ac79663": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa61fe57992243f581ae3a2be486164c",
      "max": 42068,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0afd68d6cc3e452b9995c16b45498e0c",
      "value": 42068
     }
    },
    "76435fd43d15403aa6ae09c170d08bff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "777e888395634af98a54350e9afd3173": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "798c1eca83ef4409ad5cf05ead9a55c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79f0039ff69d442fb308d2572e45568e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73800733b6e549f08c2dc81b292520c4",
      "placeholder": "​",
      "style": "IPY_MODEL_e469615a3ad143318cec11ed6ea82346",
      "value": " 72/72 [00:19&lt;00:00,  3.62it/s]"
     }
    },
    "7e51e710fe314164bd358efa9f7c553e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7f5cad4515454ac1b3cf13bafe2be8b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76435fd43d15403aa6ae09c170d08bff",
      "max": 42068,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_661ea4ef6e4c46e4930a9fe6622e15b6",
      "value": 42068
     }
    },
    "82188772d1a64ddfbf2b18049e8991f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e5a920068fd48b6b7af469c6e43b2f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "92d196ac95b34d0a9b85fde8c291c863": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93d68d9d5ae64d3cb21e70b9e60dad35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "96df479f4bce49a6ad50823ca13c7a8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a53da36e76a4c078ec997f7ecb19c53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f3cad8f4790440991d8689a6901092b",
       "IPY_MODEL_7f5cad4515454ac1b3cf13bafe2be8b7",
       "IPY_MODEL_dcf79d8ac613425fa5680359fcd55e52"
      ],
      "layout": "IPY_MODEL_96df479f4bce49a6ad50823ca13c7a8a"
     }
    },
    "9a8be20f7afd48a38aaaac982a3e020b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e3a4277f4ff40078f28d3a0abee11c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9fa143b50b4a4071966a75797331120c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04b88d3a05db465097d3b6d132b9d4d9",
      "placeholder": "​",
      "style": "IPY_MODEL_366a68482f1b4c9aace014294204a3d4",
      "value": "Traning at epoch 0:   3%"
     }
    },
    "a83a2f6476014b699354aeec51081856": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa61fe57992243f581ae3a2be486164c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aebb9ebcf3f642d1ab1cbdc27dc4765c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08888abc179e4f4db80b340adf3cefc4",
      "max": 3370,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7e51e710fe314164bd358efa9f7c553e",
      "value": 3370
     }
    },
    "b00b6b54679a43b3bdc1259ad6f0e8b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eeb84b4f6bea45a6bcadd12e6a68ee83",
       "IPY_MODEL_aebb9ebcf3f642d1ab1cbdc27dc4765c",
       "IPY_MODEL_da209ecaa8af40e6b771ec773a4596e4"
      ],
      "layout": "IPY_MODEL_d05c534b93d24537924364b5e0f90e41"
     }
    },
    "b2df758ccb7c4ce2ae4ace0d60567536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3518c5087a54b8e90271e5960d91865": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_728ff942c62e4316bee3712f83be0d4f",
      "placeholder": "​",
      "style": "IPY_MODEL_ffd343e5537b411e821e1c7d1b40fd57",
      "value": " 42068/42068 [04:51&lt;00:00, 146.97it/s]"
     }
    },
    "b508585491914913af1e97442d173c19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1282ffc696e94bde9d464c086bf56a9e",
      "placeholder": "​",
      "style": "IPY_MODEL_9e3a4277f4ff40078f28d3a0abee11c1",
      "value": " 27/920 [00:07&lt;04:09,  3.59it/s]"
     }
    },
    "b86c1938fbf54e1f9ec838d22ac8e686": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c63c7845afb448adb5e2b791aa6711f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3f98bb7355c8445c8e6f533c010723df",
       "IPY_MODEL_f7105aa135ab48fb8ba43a3b6df554a8",
       "IPY_MODEL_3545d285dd56410eb867b6bddd64bbfb"
      ],
      "layout": "IPY_MODEL_b86c1938fbf54e1f9ec838d22ac8e686"
     }
    },
    "c6971f8d9554424c90a42d04cbb42579": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61d7f90ab5d140c48dc3dd199b6acf75",
      "placeholder": "​",
      "style": "IPY_MODEL_b2df758ccb7c4ce2ae4ace0d60567536",
      "value": "unigram counting: 100%"
     }
    },
    "ceb86bd353e44e358ade1af7dd367b1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d05c534b93d24537924364b5e0f90e41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1c4dda64d4d4938ac0592eede0af27a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da209ecaa8af40e6b771ec773a4596e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82188772d1a64ddfbf2b18049e8991f0",
      "placeholder": "​",
      "style": "IPY_MODEL_546564a20a2243c1a901562e6e16357e",
      "value": " 3370/3370 [00:23&lt;00:00, 150.49it/s]"
     }
    },
    "db92112fd1404654a3f11dec95a79378": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f013dd9434e4a019af0ffcaf5bc1194",
       "IPY_MODEL_73887cb869e94589b4e5b1b691b6f937",
       "IPY_MODEL_e6f545c0008e45ff95ea610c86b10987"
      ],
      "layout": "IPY_MODEL_634379b2174944c6a2527d43d6fb21ca"
     }
    },
    "dcf4e8ce928244b8b4c07ffe0225fffc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcf79d8ac613425fa5680359fcd55e52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e5cbadd09154cae8aa3ed9cffccaecf",
      "placeholder": "​",
      "style": "IPY_MODEL_5eac3a9da9574e898c0c10b93577b244",
      "value": " 42068/42068 [00:00&lt;00:00, 471213.73it/s]"
     }
    },
    "e469615a3ad143318cec11ed6ea82346": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e69bba41e3384f19be77eb2e870ac131": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c6971f8d9554424c90a42d04cbb42579",
       "IPY_MODEL_75ad4c14843d41a18298b4580ac79663",
       "IPY_MODEL_b3518c5087a54b8e90271e5960d91865"
      ],
      "layout": "IPY_MODEL_92d196ac95b34d0a9b85fde8c291c863"
     }
    },
    "e6f545c0008e45ff95ea610c86b10987": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6be04f4c233d468595cad6b45aff8040",
      "placeholder": "​",
      "style": "IPY_MODEL_e94ddfd39d1d4e80937eb1c7257b4526",
      "value": " 42068/42068 [04:49&lt;00:00, 148.55it/s]"
     }
    },
    "e94ddfd39d1d4e80937eb1c7257b4526": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec79cb6402fb48209b04cf141b682e02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eeb84b4f6bea45a6bcadd12e6a68ee83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a8be20f7afd48a38aaaac982a3e020b",
      "placeholder": "​",
      "style": "IPY_MODEL_f7f1f75e05d34717ba63436a403541d4",
      "value": "perplexity: 100%"
     }
    },
    "eef62927dca744b0b0ac405a69077e1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4927eb77cee4fc69c897fb3911f5793": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7105aa135ab48fb8ba43a3b6df554a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a83a2f6476014b699354aeec51081856",
      "max": 3370,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_93d68d9d5ae64d3cb21e70b9e60dad35",
      "value": 3370
     }
    },
    "f7f1f75e05d34717ba63436a403541d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ffd343e5537b411e821e1c7d1b40fd57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
